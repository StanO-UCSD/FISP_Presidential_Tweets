{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hng/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import re\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## functions for lexical analysis\n",
    "\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    stems = stem_tokens(tokens,stemmer)\n",
    "    return stems\n",
    "\n",
    "def text2vec(full_text, use_stemmer=False):\n",
    "    \"\"\"\n",
    "    Convert text to vectors using TFIDF\n",
    "    ngram_range=(1,3) means unigrams, bigrams and trigrams; \n",
    "    if want to use bigrams only, define ngram_range=(2,2)\n",
    "    \n",
    "    \"\"\"\n",
    "    text=full_text[:]\n",
    "    if use_stemmer:\n",
    "        vectorizer = TfidfVectorizer(tokenizer=tokenize,ngram_range=(1,3))\n",
    "    else:\n",
    "        vectorizer = TfidfVectorizer(ngram_range=(1,3))\n",
    "    text_vector = vectorizer.fit_transform(text)\n",
    "    return text_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Load the Data\n",
    "Load \"human-coded-tweets\" into a pandas dataframe. Data preprocessing (convert to lower case, remove punctuation, remove screen names. etc) should be done before this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "np.nan is an invalid document, expected byte or unicode string.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-a5f36a5e56a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# convert the text to vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfull_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtext_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext2vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_stemmer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-9dca1074d4b4>\u001b[0m in \u001b[0;36mtext2vec\u001b[0;34m(full_text, use_stemmer)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mvectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngram_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mtext_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtext_vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hng/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1350\u001b[0m             \u001b[0mTf\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0midf\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mweighted\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mterm\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m         \"\"\"\n\u001b[0;32m-> 1352\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1353\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m         \u001b[0;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hng/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0;32m--> 839\u001b[0;31m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hng/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hng/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(doc)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m             return lambda doc: self._word_ngrams(\n\u001b[0;32m--> 241\u001b[0;31m                 tokenize(preprocess(self.decode(doc))), stop_words)\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hng/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, doc)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             raise ValueError(\"np.nan is an invalid document, expected byte or \"\n\u001b[0m\u001b[1;32m    122\u001b[0m                              \"unicode string.\")\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: np.nan is an invalid document, expected byte or unicode string."
     ]
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "data = pd.DataFrame.from_csv('ProcessedDataLowNoLinkNoPuncNoNames.csv')\n",
    "# take the 'text' column from the dataframe, and \n",
    "# convert the text to vectors\n",
    "full_text = data['text']\n",
    "text_vec = text2vec(full_text, use_stemmer=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Split the data\n",
    "Split the data into a training set and a test set. Ideally the data should be shuffled before the split to avoid implicit bias in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_train = text_vec[0:7638,] #7638 training tweets\n",
    "pred_test = text_vec[7638:,] # 725 test tweets\n",
    "pred_matrix = np.zeros((725,18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index\n",
       "1.000000e+00    the sheer size and remoteness of the federal b...\n",
       "2.000000e+00    rt pilotnews ex va gov jim gilmore not giving ...\n",
       "3.000000e+00                                listen here cruzcrew \n",
       "4.000000e+00    rt freebeacon tedcruz on jailing of christian ...\n",
       "5.000000e+00    just one candidate is in a strong position to ...\n",
       "6.000000e+00               champions welcome to nyc ussoccer wnt \n",
       "7.000000e+00    rt reprodblum today i voted no on hr2048 the u...\n",
       "8.000000e+00    thanks for joining cruzcountry see y all again...\n",
       "9.000000e+00    hey cpac john kasich s plan returns power mone...\n",
       "1.000000e+01    rt thebriefing2016 you re right johnkasich the...\n",
       "1.100000e+01    rt leedanielsent imwithher because hillaryclin...\n",
       "1.200000e+01    rt tomnocera the reagan trump images are inspi...\n",
       "1.300000e+01    humbled amp honored by the overflow crowds the...\n",
       "1.400000e+01    rt ie4bernie one hour until stay and this hous...\n",
       "1.500000e+01    this account will be run by campaign staff fro...\n",
       "1.600000e+01    looking forward to joining jaketapper and thel...\n",
       "1.700000e+01    photo gallery the first 100 days of the bernie...\n",
       "1.800000e+01    rt kevinbingle breaking the bostonglobe globeo...\n",
       "1.900000e+01    at the citadel for my speech on foreign policy...\n",
       "2.000000e+01    there are some things in washington we need to...\n",
       "2.100000e+01    rt jaketapper on thelead house gop chaos law e...\n",
       "2.200000e+01    rt foxnews randpaul we think we re going to do...\n",
       "2.300000e+01    little marco rubio treated america s ice offic...\n",
       "2.400000e+01    rt mvbarnhill two local high school seniors re...\n",
       "2.500000e+01    rt outfrontcnn governorpataki to fellow gop ca...\n",
       "2.600000e+01     votersfirst has begun tune into the unionlead...\n",
       "2.700000e+01    rt hillaryforsc we need to raise wages for the...\n",
       "2.800000e+01    how does it happen that every major country on...\n",
       "2.900000e+01    donald trump no es el nico que tiene ideas ret...\n",
       "3.000000e+01                                     votetrump video \n",
       "                                      ...                        \n",
       "8.460000e+17    thanks you for all of the trump rallies today ...\n",
       "8.600000e+17    i am watching the democrats trying to defend t...\n",
       "8.790000e+17    rt whitehouse today potus will welcome the pri...\n",
       "8.230000e+17    what truly matters is not which party controls...\n",
       "8.760000e+17    the fake news media hates when i use what has ...\n",
       "8.000000e+17    will be working all weekend in choosing the gr...\n",
       "8.210000e+17     nbcnews is bad but saturday night live is the...\n",
       "8.550000e+17                                                  NaN\n",
       "8.450000e+17    pam who is raising her grandson because his pa...\n",
       "8.550000e+17                                                  NaN\n",
       "8.540000e+17    just learned that jon ossoff who is running fo...\n",
       "8.050000e+17    wanting to sell their product cars a c units e...\n",
       "8.090000e+17    i will hold a press conference in the near fut...\n",
       "8.540000e+17    i did what was an almost an impossible thing t...\n",
       "8.470000e+17    the failing nytimes would do much better if th...\n",
       "8.870000e+17    fake news story of secret dinner with putin is...\n",
       "8.830000e+17                                                  NaN\n",
       "8.290000e+17    it is a disgrace that my full cabinet is still...\n",
       "8.680000e+17                                                  NaN\n",
       "8.230000e+17    today we are not merely transferring power fro...\n",
       "8.840000e+17                     thank you senatordole very kind \n",
       "8.240000e+17    i will be interviewed by davidmuir tonight at ...\n",
       "8.160000e+17     trump is already delivering the jobs he promi...\n",
       "8.390000e+17    122 vicious prisoners released by the obama ad...\n",
       "8.780000e+17    rt foxandfriends potus the predictor president...\n",
       "8.690000e+17    just left the g7summit had great meetings on e...\n",
       "8.180000e+17    it s finally happening fiat chrysler just anno...\n",
       "8.420000e+17    great optimism in america and the results will...\n",
       "8.120000e+17    someone incorrectly stated that the phrase dra...\n",
       "8.440000e+17    what about all of the contact with the clinton...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Pick the right models\n",
    "The classification pipeline is: fitting the model with the training set -> predict labels on the test set -> compare predicted labels to real labels(human-coded-labels). These are all done on the human-coded-tweets, for the purpose of finding the best classification model with appropriate hyper-parameter settings. \n",
    "\n",
    "These could be done in one big for-loop, but it takes a long time to run, and it did crash my computer several times. What I did was to run classifications on only a few categories at a time - there would be many repeated code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sentiment (Multinomial Naive Bayes); different alpha values would yield slightly different classification results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Can't handle mix of continuous and binary",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-2c464b27d1e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# compute standard metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtar_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mclass_report\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtar_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mkappa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcohen_kappa_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtar_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hng/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0mdiffering_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_nonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hng/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         raise ValueError(\"Can't handle mix of {0} and {1}\"\n\u001b[0;32m---> 82\u001b[0;31m                          \"\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Can't handle mix of continuous and binary"
     ]
    }
   ],
   "source": [
    "key = 'Sentiment'\n",
    "alpha = 0.4\n",
    "\n",
    "# real labels for the training set\n",
    "tar_train = data[key][0:7638,] \n",
    "# real labels for the test set\n",
    "tar_test = data[key][7638:,]\n",
    "\n",
    "# specify the classification model\n",
    "clf = MultinomialNB(alpha=alpha, fit_prior=True, class_prior=None)\n",
    "# fit the model with the training set\n",
    "clf.fit(pred_train, tar_train)\n",
    "# compute training accuracy\n",
    "train_score = clf.score(pred_train, tar_train)\n",
    "# predict labels on the test set\n",
    "y_pred = clf.predict(pred_test)\n",
    "\n",
    "# compute standard metrics\n",
    "test_accuracy = metrics.accuracy_score(tar_test, y_pred)\n",
    "class_report = metrics.classification_report(tar_test, y_pred)\n",
    "kappa = metrics.cohen_kappa_score(tar_test, y_pred)\n",
    "\n",
    "print(key)\n",
    "print('='*50)\n",
    "print('Training Accuracy: '+'{:.4f}'.format(train_score))\n",
    "print('Test Accuracy: '+'{:.4f}'.format(test_accuracy))\n",
    "print('Kappa: '+'{:.4f}'.format(kappa))\n",
    "print(class_report)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Political & Makes_a_Factual_or_Verifiable_Claim (Linear SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Political\n",
      "==================================================\n",
      "Training Accuracy: 0.9985\n",
      "Test Accuracy: 0.8662\n",
      "Kappa: 0.1062\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.00      0.00      0.00         1\n",
      "          0       0.47      0.08      0.14        95\n",
      "          1       0.88      0.99      0.93       629\n",
      "\n",
      "avg / total       0.82      0.87      0.82       725\n",
      "\n",
      "\n",
      "\n",
      "Makes_a_Factual_or_Verifiable_Claim\n",
      "==================================================\n",
      "Training Accuracy: 0.9960\n",
      "Test Accuracy: 0.7310\n",
      "Kappa: 0.3698\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.86      0.81       474\n",
      "          1       0.65      0.49      0.56       251\n",
      "\n",
      "avg / total       0.72      0.73      0.72       725\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/somebro/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "keys = ['Political', 'Makes_a_Factual_or_Verifiable_Claim']\n",
    "\n",
    "for key in keys: \n",
    "    # real labels for the training set\n",
    "    tar_train = data[key][0:6800,] \n",
    "    # real labels for the test set\n",
    "    tar_test = data[key][6800:,]\n",
    "\n",
    "    # specify the classification model\n",
    "    clf = LinearSVC(class_weight='balanced')\n",
    "    # fit the model with the training set\n",
    "    clf.fit(pred_train, tar_train)\n",
    "    # compute training accuracy\n",
    "    train_score = clf.score(pred_train, tar_train)\n",
    "    # predict labels on the test set\n",
    "    y_pred = clf.predict(pred_test)\n",
    "\n",
    "    # compute standard metrics\n",
    "    test_accuracy = metrics.accuracy_score(tar_test, y_pred)\n",
    "    class_report = metrics.classification_report(tar_test, y_pred)\n",
    "    kappa = metrics.cohen_kappa_score(tar_test, y_pred)\n",
    "\n",
    "    print(key)\n",
    "    print('='*50)\n",
    "    print('Training Accuracy: '+'{:.4f}'.format(train_score))\n",
    "    print('Test Accuracy: '+'{:.4f}'.format(test_accuracy))\n",
    "    print('Kappa: '+'{:.4f}'.format(kappa))\n",
    "    print(class_report)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ideology & Immigration & Macroeconomic & National_Security & \n",
    "Crime & Civil_Rights & Environment & Education & Health_Care (Bagging Classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ideology\n",
      "==================================================\n",
      "Training Accuracy: 0.9971\n",
      "Test Accuracy: 0.6510\n",
      "Kappa: 0.4446\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.73      0.59      0.65       144\n",
      "          0       0.52      0.63      0.57       238\n",
      "          1       0.74      0.69      0.71       343\n",
      "\n",
      "avg / total       0.66      0.65      0.65       725\n",
      "\n",
      "\n",
      "\n",
      "Immigration\n",
      "==================================================\n",
      "Training Accuracy: 0.9988\n",
      "Test Accuracy: 0.9807\n",
      "Kappa: 0.3578\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99       707\n",
      "          1       1.00      0.22      0.36        18\n",
      "\n",
      "avg / total       0.98      0.98      0.97       725\n",
      "\n",
      "\n",
      "\n",
      "Macroeconomic\n",
      "==================================================\n",
      "Training Accuracy: 0.9993\n",
      "Test Accuracy: 0.9434\n",
      "Kappa: 0.5436\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97       658\n",
      "          1       0.96      0.40      0.57        67\n",
      "\n",
      "avg / total       0.94      0.94      0.93       725\n",
      "\n",
      "\n",
      "\n",
      "National_Security\n",
      "==================================================\n",
      "Training Accuracy: 0.9991\n",
      "Test Accuracy: 0.9200\n",
      "Kappa: 0.4296\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.99      0.96       646\n",
      "          1       0.86      0.32      0.46        79\n",
      "\n",
      "avg / total       0.92      0.92      0.90       725\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kexin Chen\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crime\n",
      "==================================================\n",
      "Training Accuracy: 0.9997\n",
      "Test Accuracy: 0.9710\n",
      "Kappa: 0.0000\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.99       704\n",
      "          1       0.00      0.00      0.00        21\n",
      "\n",
      "avg / total       0.94      0.97      0.96       725\n",
      "\n",
      "\n",
      "\n",
      "Civil_Rights\n",
      "==================================================\n",
      "Training Accuracy: 0.9996\n",
      "Test Accuracy: 0.9655\n",
      "Kappa: 0.1315\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98       699\n",
      "          1       0.67      0.08      0.14        26\n",
      "\n",
      "avg / total       0.96      0.97      0.95       725\n",
      "\n",
      "\n",
      "\n",
      "Environment\n",
      "==================================================\n",
      "Training Accuracy: 1.0000\n",
      "Test Accuracy: 0.9917\n",
      "Kappa: 0.2482\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00       718\n",
      "          1       1.00      0.14      0.25         7\n",
      "\n",
      "avg / total       0.99      0.99      0.99       725\n",
      "\n",
      "\n",
      "\n",
      "Education\n",
      "==================================================\n",
      "Training Accuracy: 0.9997\n",
      "Test Accuracy: 0.9917\n",
      "Kappa: 0.2469\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00       719\n",
      "          1       0.50      0.17      0.25         6\n",
      "\n",
      "avg / total       0.99      0.99      0.99       725\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_samples=0.7\n",
    "max_features=0.8\n",
    "keys = ['Ideology', 'Immigration', 'Macroeconomic', 'National_Security', 'Crime', 'Civil_Rights',\n",
    "        'Environment', 'Education']\n",
    "\n",
    "for key in keys: \n",
    "    # real labels for the training set\n",
    "    tar_train = data[key][0:6800,] \n",
    "    # real labels for the test set\n",
    "    tar_test = data[key][6800:,]\n",
    "\n",
    "    # specify the classification model\n",
    "    clf = BaggingClassifier(LinearSVC(class_weight='balanced'), \n",
    "                            max_samples=max_samples, max_features=max_features)\n",
    "    # fit the model with the training set\n",
    "    clf.fit(pred_train, tar_train) \n",
    "    # compute training accuracy\n",
    "    train_score = clf.score(pred_train, tar_train)\n",
    "    # predict labels on the test set\n",
    "    y_pred = clf.predict(pred_test)\n",
    "\n",
    "    # compute standard metrics\n",
    "    test_accuracy = metrics.accuracy_score(tar_test, y_pred)\n",
    "    class_report = metrics.classification_report(tar_test, y_pred)\n",
    "    kappa = metrics.cohen_kappa_score(tar_test, y_pred)\n",
    "\n",
    "    print(key)\n",
    "    print('='*50)\n",
    "    print('Training Accuracy: '+'{:.4f}'.format(train_score))\n",
    "    print('Test Accuracy: '+'{:.4f}'.format(test_accuracy))\n",
    "    print('Kappa: '+'{:.4f}'.format(kappa))\n",
    "    print(class_report)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Governance & No_Policy_Content & Asks_for_Donation &  Asks_you_to_watch_something_share_something_follow_something & Misc & Expresses_an_Opinion (Bagging Classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kexin Chen\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Governance\n",
      "==================================================\n",
      "Training Accuracy: 0.9994\n",
      "Test Accuracy: 0.9697\n",
      "Kappa: 0.0000\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98       703\n",
      "          1       0.00      0.00      0.00        22\n",
      "\n",
      "avg / total       0.94      0.97      0.95       725\n",
      "\n",
      "\n",
      "\n",
      "No_Policy_Content\n",
      "==================================================\n",
      "Training Accuracy: 0.9968\n",
      "Test Accuracy: 0.7034\n",
      "Kappa: 0.3987\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.44      0.59       353\n",
      "          1       0.64      0.95      0.77       372\n",
      "\n",
      "avg / total       0.77      0.70      0.68       725\n",
      "\n",
      "\n",
      "\n",
      "Asks_for_Donation\n",
      "==================================================\n",
      "Training Accuracy: 0.9997\n",
      "Test Accuracy: 0.9848\n",
      "Kappa: 0.2631\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99       712\n",
      "          1       1.00      0.15      0.27        13\n",
      "\n",
      "avg / total       0.99      0.98      0.98       725\n",
      "\n",
      "\n",
      "\n",
      "Asks_you_to_watch_something_share_something_follow_something\n",
      "==================================================\n",
      "Training Accuracy: 0.9987\n",
      "Test Accuracy: 0.9366\n",
      "Kappa: 0.6013\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.98      0.97       651\n",
      "          1       0.77      0.54      0.63        74\n",
      "\n",
      "avg / total       0.93      0.94      0.93       725\n",
      "\n",
      "\n",
      "\n",
      "Misc\n",
      "==================================================\n",
      "Training Accuracy: 0.9962\n",
      "Test Accuracy: 0.9531\n",
      "Kappa: 0.4275\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.98      0.98       690\n",
      "          1       0.52      0.40      0.45        35\n",
      "\n",
      "avg / total       0.95      0.95      0.95       725\n",
      "\n",
      "\n",
      "\n",
      "Expresses_an_Opinion\n",
      "==================================================\n",
      "Training Accuracy: 0.9954\n",
      "Test Accuracy: 0.7269\n",
      "Kappa: 0.3706\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.51      0.57       255\n",
      "          1       0.76      0.85      0.80       470\n",
      "\n",
      "avg / total       0.72      0.73      0.72       725\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_samples=0.7\n",
    "max_features=0.8\n",
    "keys = ['Governance', 'No_Policy_Content', 'Asks_for_Donation', \n",
    "        'Asks_you_to_watch_something_share_something_follow_something',\n",
    "        'Misc', 'Expresses_an_Opinion']\n",
    "\n",
    "for key in keys: \n",
    "    # real labels for the training set\n",
    "    tar_train = data[key][0:6800,] \n",
    "    # real labels for the test set\n",
    "    tar_test = data[key][6800:,]\n",
    "\n",
    "    # specify the classification model\n",
    "    clf = BaggingClassifier(LinearSVC(class_weight='balanced'),\n",
    "                            max_samples=max_samples, max_features=max_features)\n",
    "    # fit the model with the training set\n",
    "    clf.fit(pred_train, tar_train)\n",
    "    # compute training accuracy\n",
    "    train_score = clf.score(pred_train, tar_train)\n",
    "    # predict labels on the test set\n",
    "    y_pred = clf.predict(pred_test)\n",
    "\n",
    "    # compute standard metrics\n",
    "    test_accuracy = metrics.accuracy_score(tar_test, y_pred)\n",
    "    class_report = metrics.classification_report(tar_test, y_pred)\n",
    "    kappa = metrics.cohen_kappa_score(tar_test, y_pred)\n",
    "\n",
    "    print(key)\n",
    "    print('='*50)\n",
    "    print('Training Accuracy: '+'{:.4f}'.format(train_score))\n",
    "    print('Test Accuracy: '+'{:.4f}'.format(test_accuracy))\n",
    "    print('Kappa: '+'{:.4f}'.format(kappa))\n",
    "    print(class_report)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step Four: Final Classifications\n",
    "Having the appropriate models and hyper-parameter settings, we can use the models to predict labels for the entire corpus of tweets. At this step, we take all 7525 human-coded-tweets as the training set, and the whole corpus as the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load training data and convert to a vector\n",
    "train_data = pd.DataFrame.from_csv('ProcessedDataLowNoLinkNoPuncNoNames.csv')\n",
    "train_text = train_data['text']\n",
    "vectorizer = TfidfVectorizer(tokenizer=tokenize,ngram_range=(1,3))\n",
    "pred_train = vectorizer.fit_transform(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the full corpus and convert to a vector\n",
    "final_data = pd.DataFrame.from_csv('ProcessedFullCorpus.csv')\n",
    "final_text = final_data['text']\n",
    "pred_final = vectorizer.transform(final_text.values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# specify classification models and hyper-parameter settings\n",
    "alpha = 0.1\n",
    "max_samples=0.7\n",
    "max_features=0.8\n",
    "\n",
    "def runClassifiers(classifier, pred_train, tar_train, pred_final):\n",
    "    if classifier=='NB':\n",
    "        clf = MultinomialNB(alpha=alpha, fit_prior=True, class_prior=None)\n",
    "    elif classifier=='SVC':\n",
    "        clf = LinearSVC(class_weight='balanced')\n",
    "    elif classifier=='Bag':\n",
    "        clf = BaggingClassifier(LinearSVC(class_weight='balanced'),\n",
    "                                max_samples=0.7, max_features=0.8)\n",
    "    clf.fit(pred_train,tar_train)\n",
    "    print('fit successfully')\n",
    "    y_class_final = clf.predict(pred_final)\n",
    "    print('predict successfully')\n",
    "    return y_class_final\n",
    "\n",
    "# A list hardcoded to specify the classifier to use for each category\n",
    "classifiers = ['NB','SVC','Bag','Bag','Bag','Bag','Bag','Bag','Bag',\n",
    "               'Bag','Bag','Bag','Bag','Bag','Bag','Bag','SVC','Bag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# obtain column names\n",
    "keys = [key for key in train_data if key != 'text']\n",
    "pred_matrix = np.zeros((len(final_data),18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit successfully\n",
      "predict successfully\n",
      "Sentiment Classifications Done\n",
      "--------------------------------------------------\n",
      "fit successfully\n",
      "predict successfully\n",
      "Political Classifications Done\n",
      "--------------------------------------------------\n",
      "fit successfully\n",
      "predict successfully\n",
      "Ideology Classifications Done\n",
      "--------------------------------------------------\n",
      "fit successfully\n",
      "predict successfully\n",
      "Immigration Classifications Done\n",
      "--------------------------------------------------\n",
      "fit successfully\n",
      "predict successfully\n",
      "Macroeconomic Classifications Done\n",
      "--------------------------------------------------\n",
      "fit successfully\n",
      "predict successfully\n",
      "National_Security Classifications Done\n",
      "--------------------------------------------------\n",
      "fit successfully\n",
      "predict successfully\n",
      "Crime Classifications Done\n",
      "--------------------------------------------------\n",
      "fit successfully\n",
      "predict successfully\n",
      "Civil_Rights Classifications Done\n",
      "--------------------------------------------------\n",
      "fit successfully\n",
      "predict successfully\n",
      "Environment Classifications Done\n",
      "--------------------------------------------------\n",
      "fit successfully\n",
      "predict successfully\n",
      "Education Classifications Done\n",
      "--------------------------------------------------\n",
      "fit successfully\n",
      "predict successfully\n",
      "Health_Care Classifications Done\n",
      "--------------------------------------------------\n",
      "fit successfully\n",
      "predict successfully\n",
      "Governance Classifications Done\n",
      "--------------------------------------------------\n",
      "fit successfully\n",
      "predict successfully\n",
      "No_Policy_Content Classifications Done\n",
      "--------------------------------------------------\n",
      "fit successfully\n",
      "predict successfully\n",
      "Asks_for_Donation Classifications Done\n",
      "--------------------------------------------------\n",
      "fit successfully\n",
      "predict successfully\n",
      "Asks_you_to_watch_something_share_something_follow_something Classifications Done\n",
      "--------------------------------------------------\n",
      "fit successfully\n",
      "predict successfully\n",
      "Misc Classifications Done\n",
      "--------------------------------------------------\n",
      "fit successfully\n",
      "predict successfully\n",
      "Makes_a_Factual_or_Verifiable_Claim Classifications Done\n",
      "--------------------------------------------------\n",
      "fit successfully\n",
      "predict successfully\n",
      "Expresses_an_Opinion Classifications Done\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# final classifications: save prediction results in a matrix\n",
    "for n, key in enumerate(keys):\n",
    "    tar_train = train_data[key]\n",
    "    y_final = runClassifiers(classifiers[n], pred_train, tar_train, pred_final)\n",
    "    print(key+' Classifications Done')\n",
    "    print('-'*50)\n",
    "    pred_matrix[:,n] = y_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert prediction matrix into dataframe\n",
    "final_df = pd.DataFrame(pred_matrix).astype(int)\n",
    "final_df.columns = keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Political</th>\n",
       "      <th>Ideology</th>\n",
       "      <th>Immigration</th>\n",
       "      <th>Macroeconomic</th>\n",
       "      <th>National_Security</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Civil_Rights</th>\n",
       "      <th>Environment</th>\n",
       "      <th>Education</th>\n",
       "      <th>Health_Care</th>\n",
       "      <th>Governance</th>\n",
       "      <th>No_Policy_Content</th>\n",
       "      <th>Asks_for_Donation</th>\n",
       "      <th>Asks_you_to_watch_something_share_something_follow_something</th>\n",
       "      <th>Misc</th>\n",
       "      <th>Makes_a_Factual_or_Verifiable_Claim</th>\n",
       "      <th>Expresses_an_Opinion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8282</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19782</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14342</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8769</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10674</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sentiment  Political  Ideology  Immigration  Macroeconomic  \\\n",
       "8282           0          1        -1            0              0   \n",
       "19782          1          1         1            0              0   \n",
       "14342          1          1         1            0              0   \n",
       "8769          -1          1         1            0              0   \n",
       "10674          1          1        -1            0              0   \n",
       "\n",
       "       National_Security  Crime  Civil_Rights  Environment  Education  \\\n",
       "8282                   0      0             0            0          0   \n",
       "19782                  0      0             0            0          0   \n",
       "14342                  0      0             0            0          0   \n",
       "8769                   0      0             0            0          0   \n",
       "10674                  0      0             0            0          1   \n",
       "\n",
       "       Health_Care  Governance  No_Policy_Content  Asks_for_Donation  \\\n",
       "8282             0           0                  1                  0   \n",
       "19782            0           0                  1                  0   \n",
       "14342            0           0                  1                  0   \n",
       "8769             0           0                  0                  0   \n",
       "10674            0           0                  1                  0   \n",
       "\n",
       "       Asks_you_to_watch_something_share_something_follow_something  Misc  \\\n",
       "8282                                                   0                0   \n",
       "19782                                                  1                0   \n",
       "14342                                                  1                0   \n",
       "8769                                                   0                0   \n",
       "10674                                                  0                0   \n",
       "\n",
       "       Makes_a_Factual_or_Verifiable_Claim  Expresses_an_Opinion  \n",
       "8282                                     0                     1  \n",
       "19782                                    1                     0  \n",
       "14342                                    1                     0  \n",
       "8769                                     0                     1  \n",
       "10674                                    1                     0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "final_file = pd.concat([final_data.reset_index(drop=True), final_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save prediction result to csv\n",
    "out_file = 'finalPrediction.csv'\n",
    "final_file.to_csv(out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['X',\n",
       " 'id',\n",
       " 'created_at',\n",
       " 'text',\n",
       " 'hashtag.',\n",
       " 'at.',\n",
       " 'link',\n",
       " 'retweets',\n",
       " 'favorites',\n",
       " 'full.URL',\n",
       " 'Name',\n",
       " 'Sentiment',\n",
       " 'Political',\n",
       " 'Ideology',\n",
       " 'Immigration',\n",
       " 'Macroeconomic',\n",
       " 'National_Security',\n",
       " 'Crime',\n",
       " 'Civil_Rights',\n",
       " 'Environment',\n",
       " 'Education',\n",
       " 'Health_Care',\n",
       " 'Governance',\n",
       " 'No_Policy_Content',\n",
       " 'Asks_for_Donation',\n",
       " 'Asks_you_to_watch_something_share_something_follow_something',\n",
       " 'Misc',\n",
       " 'Makes_a_Factual_or_Verifiable_Claim',\n",
       " 'Expresses_an_Opinion']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(final_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
