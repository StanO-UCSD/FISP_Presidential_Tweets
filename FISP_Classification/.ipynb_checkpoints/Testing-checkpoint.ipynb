{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from util import load_data, process_text\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import os\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def avg(l):\n",
    "    return sum(l) * 1.0 / len(l)\n",
    "\n",
    "def prior(l, label):\n",
    "    return sum(map(lambda x: x[1] == label, l)) * 1.0 / len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validation_decomp(data, group_size = 10):\n",
    "    for i in range(group_size):\n",
    "        sub_size = len(data) / group_size\n",
    "        first_half = data[:(i-1)*sub_size] if i > 0 else []\n",
    "        second_half = data[(i+1)*sub_size:] if i < group_size - 1 else []\n",
    "        train_data = first_half + second_half\n",
    "        test_data = data[i*sub_size:(i+1)*sub_size]\n",
    "        yield (train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    stems = stem_tokens(tokens, stemmer)\n",
    "    return stems\n",
    "\n",
    "def run_classifer(classifier, use_stemmer=False, dimension_reduction=False):\n",
    "    data = load_data()\n",
    "    for key in data:\n",
    "\n",
    "        accuracies = []\n",
    "        sub_acc = defaultdict(list)\n",
    "        sub_recall = defaultdict(list)\n",
    "        category = set([tweet[1] for tweet in data[key]])\n",
    "\n",
    "        for train_data, test_data in cross_validation_decomp(data[key]):\n",
    "            \n",
    "            if use_stemmer:\n",
    "                training_text = [process_text(tweet[0]) for tweet in train_data]\n",
    "                testing_text = [process_text(tweet[0]) for tweet in test_data]\n",
    "            else:\n",
    "                training_text = [tweet[0] for tweet in train_data]\n",
    "                testing_text = [tweet[0] for tweet in test_data]\n",
    "\n",
    "            training_label = [tweet[1] for tweet in train_data]\n",
    "            testing_label = [tweet[1] for tweet in test_data]\n",
    "\n",
    "            if use_stemmer:\n",
    "                vectorizer = TfidfVectorizer(tokenizer=tokenize, ngram_range=(1,3))\n",
    "            else:\n",
    "                vectorizer = TfidfVectorizer(ngram_range=(1,3))\n",
    "            training_matrix = vectorizer.fit_transform(training_text)\n",
    "            testing_matrix = vectorizer.transform(testing_text)\n",
    "\n",
    "\n",
    "            weight_mode = None\n",
    "            for label in category:\n",
    "                if prior(train_data,label) < 0.1:\n",
    "                    weight_mode = 'balanced'\n",
    "                    break\n",
    "\n",
    "            if dimension_reduction: \n",
    "                dimension_reduction = TruncatedSVD(n_components = 1000)\n",
    "                training_matrix = dimension_reduction.fit_transform(training_matrix)\n",
    "                testing_matrix = dimension_reduction.transform(testing_matrix)\n",
    "            \n",
    "            if classifier == 'LinearSVC':\n",
    "                clf = LinearSVC(class_weight = weight_mode)\n",
    "            elif classifier == 'RandomForest':\n",
    "                clf = RandomForestClassifier(n_estimators=10)\n",
    "            elif classifier == 'AdaBoostClassifier':\n",
    "                clf = AdaBoostClassifier(n_estimators=100)\n",
    "            elif classifier == 'BaggingClassifier':\n",
    "                clf = BaggingClassifier(LinearSVC(),max_samples=0.5, max_features=0.7)\n",
    "\n",
    "            clf.fit(training_matrix, training_label)\n",
    "            prediction = clf.predict(testing_matrix)\n",
    "            \n",
    "            for label in category:\n",
    "                sub_acc[label].append(sum([a[0] == a[1] and a[0] == label for a in zip(testing_label, prediction)]) * 1.0 / (sum([a == label for a in testing_label]) + 1))\n",
    "                sub_recall[label].append(sum([a[0] == a[1] and a[1] == label for a in zip(testing_label, prediction)])* 1.0 / (sum([a == label for a in prediction]) + 1))\n",
    "            accuracies.append(clf.score(testing_matrix,testing_label))\n",
    "        \n",
    "        print(\"===================\")\n",
    "        print(classifier)\n",
    "        print(key+':')\n",
    "        print(\"label     prior     accuracy  recall\")\n",
    "        for label in category:\n",
    "            print(\"%-9s%1.7f  %1.7f  %1.7f\" %(label, prior(data[key],label),avg(sub_acc[label]), avg(sub_recall[label])))\n",
    "\n",
    "        print('overall accuracy:' + str(avg(accuracies)))\n",
    "        print('\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================\n",
      "LinearSVC\n",
      "Misc__other_plea_for_action:\n",
      "label     prior     accuracy  recall\n",
      "1        0.0549339  0.4576497  0.5656736\n",
      "0        0.9450661  0.9817458  0.9676040\n",
      "overall accuracy:0.955804480652\n",
      "\n",
      "\n",
      "\n",
      "===================\n",
      "LinearSVC\n",
      "Makes_a_Factual_or_Verifiable_Claim:\n",
      "label     prior     accuracy  recall\n",
      "1        0.2945793  0.3571564  0.5915518\n",
      "0        0.7054207  0.9053897  0.7649735\n",
      "overall accuracy:0.739557739558\n",
      "\n",
      "\n",
      "\n",
      "===================\n",
      "LinearSVC\n",
      "Sentiment____1_negative__0_neutral__1_positive_:\n",
      "label     prior     accuracy  recall\n",
      "1        0.3569109  0.7260078  0.6636059\n",
      "0        0.3084416  0.4235621  0.5505926\n",
      "-1       0.3346475  0.7726313  0.6823036\n",
      "overall accuracy:0.645939675174\n",
      "\n",
      "\n",
      "\n",
      "===================\n",
      "LinearSVC\n",
      "Asks_for_Donation_Asks_you_to_buy_something_to_support_campaign:\n",
      "label     prior     accuracy  recall\n",
      "1        0.0029396  0.1166667  0.1500000\n",
      "0        0.9970604  0.9979759  0.9957775\n",
      "overall accuracy:0.997426470588\n",
      "\n",
      "\n",
      "\n",
      "===================\n",
      "LinearSVC\n",
      "Policy:\n",
      "label     prior     accuracy  recall\n",
      "0        0.7228217  0.9500935  0.8637899\n",
      "1        0.0705436  0.6685884  0.6830178\n",
      "2        0.0089928  0.2481385  0.4066667\n",
      "3        0.0831335  0.5492944  0.6798003\n",
      "4        0.0221823  0.6789899  0.7373212\n",
      "5        0.0319744  0.3039704  0.5722944\n",
      "6        0.0095923  0.3941667  0.5800000\n",
      "7        0.0211831  0.4126567  0.5860714\n",
      "8        0.0177858  0.5328474  0.7046429\n",
      "9        0.0117906  0.0645833  0.1333333\n",
      "overall accuracy:0.835\n",
      "\n",
      "\n",
      "\n",
      "===================\n",
      "LinearSVC\n",
      "Expresses_an_Opinion:\n",
      "label     prior     accuracy  recall\n",
      "1        0.6847291  0.8888609  0.7596786\n",
      "0        0.3152709  0.4175118  0.6134000\n",
      "overall accuracy:0.734482758621\n",
      "\n",
      "\n",
      "\n",
      "===================\n",
      "LinearSVC\n",
      "Political___0_no__1_yes_:\n",
      "label     prior     accuracy  recall\n",
      "1        0.8941027  0.9910502  0.9118493\n",
      "0        0.1058973  0.2354570  0.7354274\n",
      "overall accuracy:0.910359408034\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_classifer('LinearSVC', use_stemmer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "run_classifer('RandomForest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "run_classifer('AdaBoostClassifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "run_classifer('BaggingClassifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "run_classifer('LinearSVC', use_stemmer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
